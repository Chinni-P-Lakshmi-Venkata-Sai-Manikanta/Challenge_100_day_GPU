{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "72V0uJX834ld",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cabed53f-2855-4016-aefc-ea5e980313cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing prefixsum_brent_kung_algorithm.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile prefixsum_brent_kung_algorithm.cu\n",
        "\n",
        "#define LOAD_SIZE 32\n",
        "#include <iostream>\n",
        "#include <cuda_runtime.h>\n",
        "// going to code Brent-Kung algorithm\n",
        "__global__ void prefixsum_kernel(float* A,float* C,int N){\n",
        "  int threadId=threadIdx.x;\n",
        "  int i=2*blockDim.x*blockIdx.x+threadId;\n",
        "\n",
        "  //load in shared memory\n",
        "\n",
        "  __shared__ float S_A[LOAD_SIZE];\n",
        "  if (i<N){\n",
        "    S_A[threadId]=A[i];\n",
        "  }\n",
        "  if (i+blockDim.x<N){\n",
        "    S_A[threadId+blockDim.x]=A[i+blockDim.x];\n",
        "  }\n",
        "  __syncthreads();\n",
        "\n",
        "  // Print shared memory after loading\n",
        "  if (threadId == 0) {\n",
        "      printf(\"Block %d, Shared memory after loading:\\n\", blockIdx.x);\n",
        "      for (int k = 0; k < LOAD_SIZE; ++k) {\n",
        "          printf(\"%.2f \", S_A[k]);\n",
        "      }\n",
        "      printf(\"\\n\");\n",
        "  }\n",
        "  __syncthreads();\n",
        "\n",
        "\n",
        "for(int jump=1;jump<=blockDim.x;jump*=2){\n",
        "  //I need to sync the threads because I need all their values for the next iteration\n",
        "  __syncthreads();\n",
        "  int j= jump*2*(threadId+1) -1;\n",
        "  if (j<LOAD_SIZE){\n",
        "    //I think this will make the threads in the warp inactive, but just a first approximation I'm going to do it like this.\n",
        "\n",
        "    S_A[j]+=S_A[j-jump];\n",
        "  }}\n",
        "  __syncthreads();\n",
        "  // Print shared memory after prefix sum\n",
        "  if (threadId == 0) {\n",
        "      printf(\"Block %d, Shared memory after prefix sum:\\n\", blockIdx.x);\n",
        "      for (int k = 0; k < LOAD_SIZE; ++k) {\n",
        "          printf(\"%.2f \", S_A[k]);\n",
        "      }\n",
        "      printf(\"\\n\");\n",
        "  }\n",
        "  __syncthreads();\n",
        "\n",
        "//Now the reduction part\n",
        "//just by pattern recognition the tree is flipped so I assume we just flip the previous algorithm somehow.\n",
        "\n",
        "\n",
        "for(int jump=LOAD_SIZE/4;jump>=1;jump/=2){\n",
        "  //I need to sync the threads because I need all their values for the next iteration\n",
        "  __syncthreads();\n",
        "  int j= jump*2*(threadId+1) -1;\n",
        "  if (j<LOAD_SIZE-jump){\n",
        "\n",
        "     S_A[j+jump]+=S_A[j];\n",
        "  }\n",
        "  __syncthreads();\n",
        "}\n",
        "  // Print shared memory after reduction\n",
        "  if (threadId == 0) {\n",
        "      printf(\"Block %d, Shared memory after reduction:\\n\", blockIdx.x);\n",
        "      for (int k = 0; k < LOAD_SIZE; ++k) {\n",
        "          printf(\"%.2f \", S_A[k]);\n",
        "      }\n",
        "      printf(\"\\n\");\n",
        "  }\n",
        "  __syncthreads();\n",
        "\n",
        "if (i<N) C[i]=S_A[threadId];\n",
        "if (i<N-blockDim.x) C[i+blockDim.x]=S_A[threadId+blockDim.x];\n",
        "__syncthreads();\n",
        "\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "void checkCudaError(const char *message) {\n",
        "    cudaError_t error = cudaGetLastError();\n",
        "    if (error != cudaSuccess) {\n",
        "        printf(\"CUDA error (%s): %s\\n\", message, cudaGetErrorString(error));\n",
        "        exit(-1);\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "int main(){\n",
        "  int N=10;\n",
        "  float A[N],C[N];\n",
        "for (int i = 0; i < N; i++) {\n",
        "    A[i] = i + 1.0f;\n",
        "}\n",
        "  float* d_A;\n",
        "  float* d_C;\n",
        "  cudaMalloc(&d_A,N*sizeof(float));\n",
        "  cudaMalloc(&d_C,N*sizeof(float));\n",
        "  cudaMemcpy(d_A,A,N*sizeof(float),cudaMemcpyHostToDevice);\n",
        "  checkCudaError(\"Failed to copy input data to device\");\n",
        "  dim3 dimBlock(32);\n",
        "  dim3 dimGrid((N + dimBlock.x - 1) / dimBlock.x);\n",
        "  prefixsum_kernel<<<dimGrid, dimBlock>>>(d_A,d_C,N);\n",
        "  checkCudaError(\"Failed to execute the kernel\");\n",
        "  cudaDeviceSynchronize();\n",
        "  cudaMemcpy(C,d_C,N*sizeof(float),cudaMemcpyDeviceToHost);\n",
        "checkCudaError(\"Failed to copy output data to host\");\n",
        "\n",
        "cudaFree(d_A);\n",
        "cudaFree(d_C);\n",
        "\n",
        "\n",
        "//printing the results\n",
        "printf(\"A:\\n\");\n",
        "for (int i=0; i<N;i++){\n",
        "  printf(\"%.2f \", A[i]);\n",
        "\n",
        "}\n",
        "printf(\"\\nC:\\n\");\n",
        "for (int i=0; i<N;i++){\n",
        "  printf(\"%.2f \", C[i]);\n",
        "\n",
        "}\n",
        "printf(\"\\n\");\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9999782e",
        "outputId": "85ea5865-e6c2-434e-eea0-c2b7eb40d8ed"
      },
      "source": [
        "# Compile the CUDA code\n",
        "!nvcc prefixsum_brent_kung_algorithm.cu -o prefixsum_brent_kung_algorithm -gencode arch=compute_75,code=sm_75\n",
        "\n",
        "# Run the executable\n",
        "!./prefixsum_brent_kung_algorithm"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Block 0, Shared memory after loading:\n",
            "1.00 2.00 3.00 4.00 5.00 6.00 7.00 8.00 9.00 10.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \n",
            "Block 0, Shared memory after prefix sum:\n",
            "1.00 3.00 3.00 10.00 5.00 11.00 7.00 36.00 9.00 19.00 0.00 19.00 0.00 0.00 0.00 55.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 55.00 \n",
            "Block 0, Shared memory after reduction:\n",
            "1.00 3.00 6.00 10.00 15.00 21.00 28.00 36.00 45.00 55.00 55.00 55.00 55.00 55.00 55.00 55.00 55.00 55.00 55.00 55.00 55.00 55.00 55.00 55.00 55.00 55.00 55.00 55.00 55.00 55.00 55.00 55.00 \n",
            "A:\n",
            "1.00 2.00 3.00 4.00 5.00 6.00 7.00 8.00 9.00 10.00 \n",
            "C:\n",
            "1.00 3.00 6.00 10.00 15.00 21.00 28.00 36.00 45.00 55.00 \n"
          ]
        }
      ]
    }
  ]
}