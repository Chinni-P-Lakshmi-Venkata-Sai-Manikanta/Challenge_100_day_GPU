{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opafiDlo_zYF",
        "outputId": "f1e23264-dde3-4ed1-ee3e-0550b8eac65d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing partialSum.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile partialSum.cu\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void partialSumKernel(int *input, int *output, int n) {\n",
        "    // Shared memory\n",
        "    extern __shared__ int sharedMemory[];\n",
        "\n",
        "    int tid = threadIdx.x;\n",
        "    int index = blockIdx.x * blockDim.x*2 + tid;\n",
        "\n",
        "    if (index < n) {\n",
        "        // Load input into shared memory and optimize the loading to do coalescing\n",
        "        sharedMemory[tid] = input[index]+input[index+blockDim.x];\n",
        "        __syncthreads();\n",
        "\n",
        "        // Perform inclusive scan in shared memory\n",
        "        for (int stride = 1; stride < blockDim.x; stride *= 2) {\n",
        "            int temp = 0;\n",
        "            if (tid >= stride) {\n",
        "                temp = sharedMemory[tid - stride];\n",
        "            }\n",
        "            __syncthreads();\n",
        "            sharedMemory[tid] += temp;\n",
        "            __syncthreads();\n",
        "            printf(\"Block %d, Thread %d, Stride %d, Shared Memory Value: %d\\n\", blockIdx.x, tid, stride, sharedMemory[tid]);\n",
        "        }\n",
        "\n",
        "        // Write result to global memory\n",
        "        output[index] = sharedMemory[tid];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    const int N = 16;\n",
        "    const int blockSize = 8;\n",
        "\n",
        "    int h_input[N] = {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16};\n",
        "    int h_output[N];\n",
        "\n",
        "    int *d_input, *d_output;\n",
        "    size_t size = N * sizeof(int);\n",
        "\n",
        "    cudaMalloc(&d_input, size);\n",
        "    cudaMalloc(&d_output, size);\n",
        "\n",
        "    cudaMemcpy(d_input, h_input, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    partialSumKernel<<<N / blockSize, blockSize, blockSize * sizeof(int)>>>(d_input, d_output, N);\n",
        "\n",
        "    cudaMemcpy(h_output, d_output, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "\n",
        "    printf(\"Input: \");\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        printf(\"%d \", h_input[i]);\n",
        "    }\n",
        "    printf(\"\\nOutput: \");\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        printf(\"%d \", h_output[i]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "\n",
        "    cudaFree(d_input);\n",
        "    cudaFree(d_output);\n",
        "\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile with the specified architecture\n",
        "!nvcc partialSum.cu -o partialSum -gencode arch=compute_75,code=sm_75\n",
        "\n",
        "# Run the executable\n",
        "!./partialSum"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfWi1ExBBEqp",
        "outputId": "a66bfe86-f379-4f52-95f8-7205583b959d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Block 0, Thread 0, Stride 1, Shared Memory Value: 10\n",
            "Block 0, Thread 1, Stride 1, Shared Memory Value: 22\n",
            "Block 0, Thread 2, Stride 1, Shared Memory Value: 26\n",
            "Block 0, Thread 3, Stride 1, Shared Memory Value: 30\n",
            "Block 0, Thread 4, Stride 1, Shared Memory Value: 34\n",
            "Block 0, Thread 5, Stride 1, Shared Memory Value: 38\n",
            "Block 0, Thread 6, Stride 1, Shared Memory Value: 42\n",
            "Block 0, Thread 7, Stride 1, Shared Memory Value: 46\n",
            "Block 0, Thread 0, Stride 2, Shared Memory Value: 10\n",
            "Block 0, Thread 1, Stride 2, Shared Memory Value: 22\n",
            "Block 0, Thread 2, Stride 2, Shared Memory Value: 36\n",
            "Block 0, Thread 3, Stride 2, Shared Memory Value: 52\n",
            "Block 0, Thread 4, Stride 2, Shared Memory Value: 60\n",
            "Block 0, Thread 5, Stride 2, Shared Memory Value: 68\n",
            "Block 0, Thread 6, Stride 2, Shared Memory Value: 76\n",
            "Block 0, Thread 7, Stride 2, Shared Memory Value: 84\n",
            "Block 0, Thread 0, Stride 4, Shared Memory Value: 10\n",
            "Block 0, Thread 1, Stride 4, Shared Memory Value: 22\n",
            "Block 0, Thread 2, Stride 4, Shared Memory Value: 36\n",
            "Block 0, Thread 3, Stride 4, Shared Memory Value: 52\n",
            "Block 0, Thread 4, Stride 4, Shared Memory Value: 70\n",
            "Block 0, Thread 5, Stride 4, Shared Memory Value: 90\n",
            "Block 0, Thread 6, Stride 4, Shared Memory Value: 112\n",
            "Block 0, Thread 7, Stride 4, Shared Memory Value: 136\n",
            "Input: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 \n",
            "Output: 10 22 36 52 70 90 112 136 0 0 0 0 0 0 0 0 \n"
          ]
        }
      ]
    }
  ]
}